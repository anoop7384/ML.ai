{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom tqdm.auto import tqdm\nfrom sklearn.metrics import mean_squared_error\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-20T06:17:10.373088Z","iopub.execute_input":"2023-06-20T06:17:10.373553Z","iopub.status.idle":"2023-06-20T06:17:10.384707Z","shell.execute_reply.started":"2023-06-20T06:17:10.373520Z","shell.execute_reply":"2023-06-20T06:17:10.383026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/input/practice-hackathon/Train.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-06-20T06:17:10.386701Z","iopub.execute_input":"2023-06-20T06:17:10.387103Z","iopub.status.idle":"2023-06-20T06:17:10.414187Z","shell.execute_reply.started":"2023-06-20T06:17:10.387071Z","shell.execute_reply":"2023-06-20T06:17:10.412613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_df.shape)","metadata":{"execution":{"iopub.status.busy":"2023-06-20T06:17:10.416237Z","iopub.execute_input":"2023-06-20T06:17:10.416872Z","iopub.status.idle":"2023-06-20T06:17:10.423665Z","shell.execute_reply.started":"2023-06-20T06:17:10.416835Z","shell.execute_reply":"2023-06-20T06:17:10.422005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-06-20T06:17:10.425347Z","iopub.execute_input":"2023-06-20T06:17:10.425736Z","iopub.status.idle":"2023-06-20T06:17:10.450417Z","shell.execute_reply.started":"2023-06-20T06:17:10.425701Z","shell.execute_reply":"2023-06-20T06:17:10.449202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.columns","metadata":{"execution":{"iopub.status.busy":"2023-06-20T06:17:10.452760Z","iopub.execute_input":"2023-06-20T06:17:10.453538Z","iopub.status.idle":"2023-06-20T06:17:10.470666Z","shell.execute_reply.started":"2023-06-20T06:17:10.453490Z","shell.execute_reply":"2023-06-20T06:17:10.469070Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2023-06-20T06:17:10.472687Z","iopub.execute_input":"2023-06-20T06:17:10.473172Z","iopub.status.idle":"2023-06-20T06:17:10.490249Z","shell.execute_reply.started":"2023-06-20T06:17:10.473138Z","shell.execute_reply":"2023-06-20T06:17:10.488827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Label encoding column A of our dataset\nfrom sklearn import preprocessing\n  \n# label_encoder object knows \n# how to understand word labels.\nlabel_encoder = preprocessing.LabelEncoder()\n  \n# Encode labels in column 'species'.\ntrain_df['A']= label_encoder.fit_transform(train_df['A'])\n  \ntrain_df['A'].unique()","metadata":{"execution":{"iopub.status.busy":"2023-06-20T06:17:10.494254Z","iopub.execute_input":"2023-06-20T06:17:10.494944Z","iopub.status.idle":"2023-06-20T06:17:10.506047Z","shell.execute_reply.started":"2023-06-20T06:17:10.494874Z","shell.execute_reply":"2023-06-20T06:17:10.504818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Iterate over the columns (excluding the target column)\nfor column in train_df.columns:\n    if column != 'Target':\n        # Create a scatter plot of the column against the target variable\n        plt.scatter(train_df[column], train_df['Target'])\n        plt.xlabel(column)\n        plt.ylabel('Target')\n        plt.title(f'{column} vs. Target')\n        plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-06-20T06:17:10.507769Z","iopub.execute_input":"2023-06-20T06:17:10.508593Z","iopub.status.idle":"2023-06-20T06:17:12.679887Z","shell.execute_reply.started":"2023-06-20T06:17:10.508552Z","shell.execute_reply":"2023-06-20T06:17:12.679073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = train_df.drop(['Target'], axis=1)\ny = train_df['Target']","metadata":{"execution":{"iopub.status.busy":"2023-06-20T06:17:12.680971Z","iopub.execute_input":"2023-06-20T06:17:12.681722Z","iopub.status.idle":"2023-06-20T06:17:12.687722Z","shell.execute_reply.started":"2023-06-20T06:17:12.681686Z","shell.execute_reply":"2023-06-20T06:17:12.686463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\n\n\ncolumns_to_scale = ['B', 'C','D','E','F','G','H'];\n\n# Step 2: Separate the columns to be scaled\nX_scaled = X\nX_temp = X_scaled[columns_to_scale]\n\n# Step 3: Apply Min-Max scaling to the selected columns\nscaler = MinMaxScaler(feature_range=(0, 1))\nX_temp = scaler.fit_transform(X_temp)\n\n# Step 4: Replace the scaled columns in the original DataFrame\nX_scaled[columns_to_scale] = X_temp\n\n# Print the resulting DataFrame with scaled columns\nprint(X,X_scaled)\ncolumn_ranges = X_scaled.describe().loc[['min', 'max']]\nprint(column_ranges)\n\nselected_columns = ['B', 'C','D','E','F','G','H'] \nX_scaled=X_scaled[selected_columns]\n\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size = 0.3)","metadata":{"execution":{"iopub.status.busy":"2023-06-20T06:17:12.689032Z","iopub.execute_input":"2023-06-20T06:17:12.689499Z","iopub.status.idle":"2023-06-20T06:17:12.745631Z","shell.execute_reply.started":"2023-06-20T06:17:12.689470Z","shell.execute_reply":"2023-06-20T06:17:12.744498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.describe()","metadata":{"execution":{"iopub.status.busy":"2023-06-20T06:17:12.749224Z","iopub.execute_input":"2023-06-20T06:17:12.749639Z","iopub.status.idle":"2023-06-20T06:17:12.782682Z","shell.execute_reply.started":"2023-06-20T06:17:12.749607Z","shell.execute_reply":"2023-06-20T06:17:12.781591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(y_train.value_counts())\n","metadata":{"execution":{"iopub.status.busy":"2023-06-20T06:17:12.783893Z","iopub.execute_input":"2023-06-20T06:17:12.784793Z","iopub.status.idle":"2023-06-20T06:17:12.790754Z","shell.execute_reply.started":"2023-06-20T06:17:12.784753Z","shell.execute_reply":"2023-06-20T06:17:12.789749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Create an instance of LinearRegression\nlinear_regression = LinearRegression()\n\n# Train the linear regression model\nlinear_regression.fit(X_train, y_train)\n\n# Predict the target variable for the test set\ny_val = linear_regression.predict(X_test)\n\n# Evaluate the model using mean squared error\nmse = mean_squared_error(y_test, y_val)\nprint(mse)","metadata":{"execution":{"iopub.status.busy":"2023-06-20T06:17:12.792227Z","iopub.execute_input":"2023-06-20T06:17:12.793068Z","iopub.status.idle":"2023-06-20T06:17:12.816604Z","shell.execute_reply.started":"2023-06-20T06:17:12.793039Z","shell.execute_reply":"2023-06-20T06:17:12.815451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\ndef train_and_predict(models, X, y, test_size):\n    \"\"\"\n    Train and predict using multiple machine learning models.\n\n    Args:\n    - models (dict): A dictionary containing the model names as keys and the corresponding model instances as values.\n    - X (array-like): The input features.\n    - y (array-like): The target variable.\n    - test_size (float): The proportion of the dataset to include in the test split (default: 0.2).\n\n    Returns:\n    - predictions (dict): A dictionary containing the model names as keys and the corresponding predicted labels as values.\n    - accuracies (dict): A dictionary containing the model names as keys and the corresponding accuracy scores as values.\n    \"\"\"\n\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size,random_state=42)\n\n    predictions = {}\n    accuracies = {}\n\n    for model_name, model in models.items():\n        # Train the model\n        model.fit(X_train, y_train)\n\n        # Predict on the test set\n        y_pred = model.predict(X_test)\n\n        # Store the predictions\n        predictions[model_name] = y_pred\n\n        # Calculate the accuracy score\n        accuracy = accuracy_score(y_test, y_pred)\n\n        # Store the accuracy score\n        accuracies[model_name] = accuracy\n\n    return predictions, accuracies","metadata":{"_kg_hide-output":false,"execution":{"iopub.status.busy":"2023-06-20T06:17:12.818088Z","iopub.execute_input":"2023-06-20T06:17:12.818467Z","iopub.status.idle":"2023-06-20T06:17:12.826288Z","shell.execute_reply.started":"2023-06-20T06:17:12.818430Z","shell.execute_reply":"2023-06-20T06:17:12.825170Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.pipeline import make_pipeline\n\nlogistic_regression = LogisticRegression()\ndecision_tree = DecisionTreeClassifier()\nrandom_forest = RandomForestClassifier()\nsvm = SVC()\nknn = KNeighborsClassifier()\nnaive_bayes = GaussianNB()\n\n\n# Polynomial Regression\npolynomial_regression = make_pipeline(PolynomialFeatures(degree=2), LinearRegression())\n\n# Create a dictionary of models\nmodels = {\n#     'Logistic Regression': logistic_regression,\n#     'Decision Tree': decision_tree,\n    'Random Forest': random_forest,\n    'Support Vector Machine': svm,\n#     'K-Nearest Neighbors': knn,\n    'Naive Bayes': naive_bayes,\n#     'Polynomial Regression': polynomial_regression\n}\n# # Assuming you have your feature matrix X and integer target variable y\n# predictions, accuracies = train_and_predict(models, X_scaled, y,0.3)\n\n# # Access the predictions and accuracies for each classifier\n# for classifier_name, y_pred in predictions.items():\n#     print(f\"Classifier: {classifier_name}\")\n# #     print(f\"Predictions: {y_pred}\")\n#     print(f\"Accuracy: {accuracies[classifier_name]}\")\n#     print()\n","metadata":{"execution":{"iopub.status.busy":"2023-06-20T06:17:12.827894Z","iopub.execute_input":"2023-06-20T06:17:12.828312Z","iopub.status.idle":"2023-06-20T06:17:12.844232Z","shell.execute_reply.started":"2023-06-20T06:17:12.828277Z","shell.execute_reply":"2023-06-20T06:17:12.842995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\n\n\ncolumns_to_scale = ['B', 'C','D','E','F','G','H'];\n\n# Step 2: Separate the columns to be scaled\nX_scaled = X\nX_temp = X_scaled[columns_to_scale]\n\n# Step 3: Apply Min-Max scaling to the selected columns\nscaler = MinMaxScaler(feature_range=(0, 1))\nX_temp = scaler.fit_transform(X_temp)\n\n# Step 4: Replace the scaled columns in the original DataFrame\nX_scaled[columns_to_scale] = X_temp\n\n# Print the resulting DataFrame with scaled columns\nprint(X,X_scaled)\ncolumn_ranges = X_scaled.describe().loc[['min', 'max']]\nprint(column_ranges)\n\nselected_columns = ['B', 'C','D','E','F','G','H'] \nX_scaled=X_scaled[selected_columns]\n\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size = 0.3)","metadata":{"execution":{"iopub.status.busy":"2023-06-20T06:17:12.845715Z","iopub.execute_input":"2023-06-20T06:17:12.846382Z","iopub.status.idle":"2023-06-20T06:17:12.905731Z","shell.execute_reply.started":"2023-06-20T06:17:12.846349Z","shell.execute_reply":"2023-06-20T06:17:12.904493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\n\n# Create an SVM classifier object\nclassifier = SVC(C= 4100,\n    kernel= 'rbf',\n    gamma= 'auto')\n\n# Train the SVM model on the training data\nclassifier.fit(X_train, y_train)\n\ny_val = classifier.predict(X_test)\n# Calculate evaluation metrics\naccuracy = accuracy_score(y_test, y_val)\nprecision = precision_score(y_test, y_val, average='macro')\nrecall = recall_score(y_test, y_val, average='macro')\nf1 = f1_score(y_test, y_val, average='macro')\n\n# Print the evaluation metrics\nprint(\"Accuracy:\", accuracy)\nprint(\"Precision:\", precision)\nprint(\"Recall:\", recall)\nprint(\"F1-score:\", f1)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-20T06:17:12.907635Z","iopub.execute_input":"2023-06-20T06:17:12.908077Z","iopub.status.idle":"2023-06-20T06:17:13.944418Z","shell.execute_reply.started":"2023-06-20T06:17:12.908038Z","shell.execute_reply":"2023-06-20T06:17:13.943283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data = pd.read_csv(\"/kaggle/input/practice-hackathon/Test.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-06-20T06:17:13.946075Z","iopub.execute_input":"2023-06-20T06:17:13.946379Z","iopub.status.idle":"2023-06-20T06:17:13.957716Z","shell.execute_reply.started":"2023-06-20T06:17:13.946354Z","shell.execute_reply":"2023-06-20T06:17:13.956296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data.shape","metadata":{"execution":{"iopub.status.busy":"2023-06-20T06:17:13.959750Z","iopub.execute_input":"2023-06-20T06:17:13.960236Z","iopub.status.idle":"2023-06-20T06:17:13.968040Z","shell.execute_reply.started":"2023-06-20T06:17:13.960186Z","shell.execute_reply":"2023-06-20T06:17:13.966978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data.head()","metadata":{"execution":{"iopub.status.busy":"2023-06-20T06:17:13.970110Z","iopub.execute_input":"2023-06-20T06:17:13.970535Z","iopub.status.idle":"2023-06-20T06:17:13.990307Z","shell.execute_reply.started":"2023-06-20T06:17:13.970497Z","shell.execute_reply":"2023-06-20T06:17:13.989202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data['A']= label_encoder.fit_transform(test_data['A'])","metadata":{"execution":{"iopub.status.busy":"2023-06-20T06:17:13.994887Z","iopub.execute_input":"2023-06-20T06:17:13.995334Z","iopub.status.idle":"2023-06-20T06:17:14.001351Z","shell.execute_reply.started":"2023-06-20T06:17:13.995294Z","shell.execute_reply":"2023-06-20T06:17:14.000425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Index=test_data['Index']\ntest_data.drop(['Index'],axis=1,inplace=True)\ntest_data.drop(['A'],axis=1,inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-06-20T06:17:14.002533Z","iopub.execute_input":"2023-06-20T06:17:14.005531Z","iopub.status.idle":"2023-06-20T06:17:14.016728Z","shell.execute_reply.started":"2023-06-20T06:17:14.005497Z","shell.execute_reply":"2023-06-20T06:17:14.015546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n# Predict the labels for the test set\ny_pred = classifier.predict(test_data)\ny_pred=pd.DataFrame(y_pred)\n\n# Calculate evaluation metrics\n# accuracy = accuracy_score(y_test, y_pred)\n# precision = precision_score(y_test, y_pred)\n# recall = recall_score(y_test, y_pred)\n# f1 = f1_score(y_test, y_pred)\n\n# Print the evaluation metrics\n# print(\"Accuracy:\", accuracy)\n# print(\"Precision:\", precision)\n# print(\"Recall:\", recall)\n# print(\"F1-score:\", f1)\nprint(y_pred.value_counts())\ny_pred.describe()","metadata":{"execution":{"iopub.status.busy":"2023-06-20T06:17:14.018010Z","iopub.execute_input":"2023-06-20T06:17:14.018309Z","iopub.status.idle":"2023-06-20T06:17:14.241283Z","shell.execute_reply.started":"2023-06-20T06:17:14.018284Z","shell.execute_reply":"2023-06-20T06:17:14.240140Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# y_test = lr.predict(test_data)","metadata":{"execution":{"iopub.status.busy":"2023-06-20T06:17:14.242829Z","iopub.execute_input":"2023-06-20T06:17:14.243643Z","iopub.status.idle":"2023-06-20T06:17:14.249080Z","shell.execute_reply.started":"2023-06-20T06:17:14.243602Z","shell.execute_reply":"2023-06-20T06:17:14.247443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result = pd.DataFrame(Index, columns = ['Index'])\nresult['Target']= y_pred\n","metadata":{"execution":{"iopub.status.busy":"2023-06-20T06:17:14.251151Z","iopub.execute_input":"2023-06-20T06:17:14.251695Z","iopub.status.idle":"2023-06-20T06:17:14.263257Z","shell.execute_reply.started":"2023-06-20T06:17:14.251652Z","shell.execute_reply":"2023-06-20T06:17:14.262001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result","metadata":{"execution":{"iopub.status.busy":"2023-06-20T06:17:14.265239Z","iopub.execute_input":"2023-06-20T06:17:14.265951Z","iopub.status.idle":"2023-06-20T06:17:14.284023Z","shell.execute_reply.started":"2023-06-20T06:17:14.265886Z","shell.execute_reply":"2023-06-20T06:17:14.282682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result.to_csv(\"submission1.csv\", index=False) #(for making submission file)","metadata":{"execution":{"iopub.status.busy":"2023-06-20T06:17:14.285826Z","iopub.execute_input":"2023-06-20T06:17:14.286321Z","iopub.status.idle":"2023-06-20T06:17:14.295392Z","shell.execute_reply.started":"2023-06-20T06:17:14.286275Z","shell.execute_reply":"2023-06-20T06:17:14.294339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}